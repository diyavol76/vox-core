{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load spectrogram images into a data loader for training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 7985\n",
      "    Root location: ./data/spectrograms\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(201, 81), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/spectrograms' #looking in subfolder train\n",
    "\n",
    "yes_no_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((201,81)),\n",
    "                                  transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(yes_no_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'no': 0, 'yes': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=yes_no_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the data for training and testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 6388\n",
      "Testing size: 1597\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(yes_no_dataset))\n",
    "test_size = len(yes_no_dataset) - train_size\n",
    "yes_no_train_dataset, yes_no_test_dataset = torch.utils.data.random_split(yes_no_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(yes_no_train_dataset))\n",
    "print(\"Testing size:\",len(yes_no_test_dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({0: 3155, 1: 3233})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in yes_no_train_dataset]\n",
    "Counter(train_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    yes_no_train_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    yes_no_test_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1373, 0.1412, 0.1333, 0.1647, 0.1294, 0.1294, 0.1686, 0.1333, 0.1686,\n",
      "        0.1529, 0.1294, 0.1176, 0.2353, 0.1333, 0.1490, 0.1412, 0.1529, 0.1333,\n",
      "        0.1882, 0.2196, 0.2392, 0.1647, 0.2392, 0.3176, 0.2667, 0.1686, 0.1882,\n",
      "        0.1255, 0.2784, 0.3333, 0.2510, 0.2510, 0.2392, 0.1529, 0.3843, 0.3686,\n",
      "        0.4039, 0.2431, 0.1647, 0.3922, 0.3686, 0.1255, 0.1804, 0.2078, 0.1294,\n",
      "        0.2235, 0.2392, 0.1647, 0.1451, 0.1451, 0.1529, 0.1373, 0.2431, 0.3098,\n",
      "        0.2784, 0.1725, 0.3020, 0.1843, 0.2235, 0.2314, 0.1725, 0.2784, 0.2667,\n",
      "        0.1255, 0.1725, 0.1569, 0.1216, 0.1294, 0.1216, 0.1176, 0.1255, 0.1333,\n",
      "        0.1216, 0.1255, 0.1922, 0.1176, 0.1490, 0.1216, 0.1216, 0.1255, 0.1176])\n"
     ]
    }
   ],
   "source": [
    "td = train_dataloader.dataset[0][0][0][0]\n",
    "print(td)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the convolutional neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(51136, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "model = CNNet().to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create train and test functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.693513  [    0/ 6388]\n",
      "loss: 0.505987  [ 1500/ 6388]\n",
      "loss: 0.560299  [ 3000/ 6388]\n",
      "loss: 0.158439  [ 4500/ 6388]\n",
      "loss: 0.166143  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 91.7%, avg loss: 0.013633\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.487377  [    0/ 6388]\n",
      "loss: 0.247089  [ 1500/ 6388]\n",
      "loss: 0.087810  [ 3000/ 6388]\n",
      "loss: 0.257693  [ 4500/ 6388]\n",
      "loss: 0.193578  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 93.0%, avg loss: 0.010607\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.188884  [    0/ 6388]\n",
      "loss: 0.144731  [ 1500/ 6388]\n",
      "loss: 0.289118  [ 3000/ 6388]\n",
      "loss: 0.151750  [ 4500/ 6388]\n",
      "loss: 0.122622  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 93.4%, avg loss: 0.009964\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.098662  [    0/ 6388]\n",
      "loss: 0.053314  [ 1500/ 6388]\n",
      "loss: 0.139524  [ 3000/ 6388]\n",
      "loss: 0.260953  [ 4500/ 6388]\n",
      "loss: 0.042041  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.1%, avg loss: 0.009297\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.173291  [    0/ 6388]\n",
      "loss: 0.060354  [ 1500/ 6388]\n",
      "loss: 0.111548  [ 3000/ 6388]\n",
      "loss: 0.208552  [ 4500/ 6388]\n",
      "loss: 0.134894  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.1%, avg loss: 0.008595\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.093208  [    0/ 6388]\n",
      "loss: 0.118718  [ 1500/ 6388]\n",
      "loss: 0.340167  [ 3000/ 6388]\n",
      "loss: 0.107207  [ 4500/ 6388]\n",
      "loss: 0.037997  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.4%, avg loss: 0.008882\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.043725  [    0/ 6388]\n",
      "loss: 0.041599  [ 1500/ 6388]\n",
      "loss: 0.054847  [ 3000/ 6388]\n",
      "loss: 0.053287  [ 4500/ 6388]\n",
      "loss: 0.059326  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.4%, avg loss: 0.008342\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.118265  [    0/ 6388]\n",
      "loss: 0.027892  [ 1500/ 6388]\n",
      "loss: 0.068567  [ 3000/ 6388]\n",
      "loss: 0.052066  [ 4500/ 6388]\n",
      "loss: 0.513224  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.5%, avg loss: 0.008269\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.066548  [    0/ 6388]\n",
      "loss: 0.057667  [ 1500/ 6388]\n",
      "loss: 0.077384  [ 3000/ 6388]\n",
      "loss: 0.097797  [ 4500/ 6388]\n",
      "loss: 0.059697  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.6%, avg loss: 0.007853\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.071769  [    0/ 6388]\n",
      "loss: 0.137719  [ 1500/ 6388]\n",
      "loss: 0.383443  [ 3000/ 6388]\n",
      "loss: 0.131534  [ 4500/ 6388]\n",
      "loss: 0.238916  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.2%, avg loss: 0.008026\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.091750  [    0/ 6388]\n",
      "loss: 0.182672  [ 1500/ 6388]\n",
      "loss: 0.117361  [ 3000/ 6388]\n",
      "loss: 0.029284  [ 4500/ 6388]\n",
      "loss: 0.075001  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.9%, avg loss: 0.007932\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.001618  [    0/ 6388]\n",
      "loss: 0.103017  [ 1500/ 6388]\n",
      "loss: 0.061418  [ 3000/ 6388]\n",
      "loss: 0.392635  [ 4500/ 6388]\n",
      "loss: 0.066901  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 94.9%, avg loss: 0.007420\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.073054  [    0/ 6388]\n",
      "loss: 0.021443  [ 1500/ 6388]\n",
      "loss: 0.141286  [ 3000/ 6388]\n",
      "loss: 0.029449  [ 4500/ 6388]\n",
      "loss: 0.326350  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.0%, avg loss: 0.007533\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.011198  [    0/ 6388]\n",
      "loss: 0.140245  [ 1500/ 6388]\n",
      "loss: 0.115683  [ 3000/ 6388]\n",
      "loss: 0.060925  [ 4500/ 6388]\n",
      "loss: 0.139895  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.6%, avg loss: 0.007418\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.008527  [    0/ 6388]\n",
      "loss: 0.268154  [ 1500/ 6388]\n",
      "loss: 0.258360  [ 3000/ 6388]\n",
      "loss: 0.161720  [ 4500/ 6388]\n",
      "loss: 0.158606  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.4%, avg loss: 0.007165\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/opt/homebrew/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nCNNet                                    [15, 2]                   --\n├─Conv2d: 1-1                            [15, 32, 197, 77]         2,432\n├─Conv2d: 1-2                            [15, 64, 94, 34]          51,264\n├─Dropout2d: 1-3                         [15, 64, 94, 34]          --\n├─Flatten: 1-4                           [15, 51136]               --\n├─Linear: 1-5                            [15, 50]                  2,556,850\n├─Linear: 1-6                            [15, 2]                   102\n==========================================================================================\nTotal params: 2,610,648\nTrainable params: 2,610,648\nNon-trainable params: 0\nTotal mult-adds (G): 3.05\n==========================================================================================\nInput size (MB): 2.93\nForward/backward pass size (MB): 82.80\nParams size (MB): 10.44\nEstimated Total Size (MB): 96.17\n=========================================================================================="
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(15, 3, 201, 81))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#### Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:\n",
      "value=0, class_name= no\n",
      "\n",
      "Actual:\n",
      "value=0, class_name= no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "class_map = ['no', 'yes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        pred = model(X)\n",
    "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),class_map[pred[0].argmax(0)]))\n",
    "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(Y[0],class_map[Y[0]]))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
